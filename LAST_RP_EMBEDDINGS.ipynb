{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "def263b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "from torch_geometric import loader\n",
    "\n",
    "dataset = PygNodePropPredDataset(name = \"ogbn-products\", root = 'dataset/')\n",
    " \n",
    "split_idx = dataset.get_idx_split()\n",
    "data = dataset[0]\n",
    "\n",
    "# Convert split indices to boolean masks and add them to `data`.\n",
    "for key, idx in split_idx.items():\n",
    "    mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    mask[idx] = True\n",
    "    data[f'{key}_mask'] = mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eecf52f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj(row, col, N, asymm_norm=False, set_diag=True, remove_diag=False):\n",
    "    \n",
    "    adj = SparseTensor(row=row, col=col, sparse_sizes=(N, N))\n",
    "    if set_diag:\n",
    "        print('... setting diagonal entries')\n",
    "        adj = adj.set_diag()\n",
    "    elif remove_diag:\n",
    "        print('... removing diagonal entries')\n",
    "        adj = adj.remove_diag()\n",
    "    else:\n",
    "        print('... keeping diag elements as they are')\n",
    "    if not asymm_norm:\n",
    "        print('... performing symmetric normalization')\n",
    "        deg = adj.sum(dim=1).to(torch.float)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        adj = deg_inv_sqrt.view(-1, 1) * adj * deg_inv_sqrt.view(1, -1)\n",
    "    else:\n",
    "        print('... performing asymmetric normalization')\n",
    "        deg = adj.sum(dim=1).to(torch.float)\n",
    "        deg_inv = deg.pow(-1.0)\n",
    "        deg_inv[deg_inv == float('inf')] = 0\n",
    "        adj = deg_inv.view(-1, 1) * adj\n",
    "\n",
    "    adj = adj.to_scipy(layout='csr')\n",
    "    \n",
    "    return adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b9e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def maybe_num_nodes(edge_index, num_nodes=None):\n",
    "    if num_nodes is not None:\n",
    "        return num_nodes\n",
    "    elif isinstance(edge_index, Tensor):\n",
    "        return int(edge_index.max()) + 1 if edge_index.numel() > 0 else 0\n",
    "    else:\n",
    "        return max(edge_index.size(0), edge_index.size(1))\n",
    "\n",
    "def dropout_adj(edge_index, edge_attr=None, p=0.5, force_undirected=False,\n",
    "                num_nodes=None, training=True):\n",
    "\n",
    "    if p < 0. or p > 1.:\n",
    "        raise ValueError('Dropout probability has to be between 0 and 1, '\n",
    "                         'but got {}'.format(p))\n",
    "\n",
    "    if not training or p == 0.0:\n",
    "        return edge_index, edge_attr\n",
    "\n",
    "    N = maybe_num_nodes(edge_index, num_nodes)\n",
    "    row, col = edge_index\n",
    "\n",
    "    if force_undirected:\n",
    "        row, col, edge_attr = filter_adj(row, col, edge_attr, row < col)\n",
    "\n",
    "    mask = edge_index.new_full((row.size(0), ), 1 - p, dtype=torch.float)\n",
    "    mask = torch.bernoulli(mask).to(torch.bool)\n",
    "\n",
    "    row, col, edge_attr = filter_adj(row, col, edge_attr, mask)\n",
    "\n",
    "    if force_undirected:\n",
    "        edge_index = torch.stack(\n",
    "            [torch.cat([row, col], dim=0),\n",
    "             torch.cat([col, row], dim=0)], dim=0)\n",
    "        if edge_attr is not None:\n",
    "            edge_attr = torch.cat([edge_attr, edge_attr], dim=0)\n",
    "        edge_index, edge_attr = coalesce(edge_index, edge_attr, N, N)\n",
    "    else:\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    return edge_index, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf4c41d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing\n",
      "Getting adj matrix\n",
      "... setting diagonal entries\n",
      "... performing symmetric normalization\n",
      "Diffusing node features\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_sparse import SparseTensor\n",
    "from torch_geometric.utils import to_undirected, dropout_adj\n",
    "\n",
    "import random\n",
    "from torch_geometric import loader\n",
    "\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "\n",
    "x = data.x.numpy()\n",
    "N = data.num_nodes\n",
    "\n",
    "print('Start processing')\n",
    "\n",
    "# print('Preparing undirected operators...')\n",
    "# edge_index, _ = dropout_adj(data.edge_index, p=0.4, num_nodes=data.num_nodes)\n",
    "\n",
    "# # to undirected\n",
    "# print('Making the graph undirected')\n",
    "# edge_index = to_undirected(edge_index, data.num_nodes)\n",
    "# row, col = edge_index\n",
    "\n",
    "# get adj\n",
    "print('Getting adj matrix')\n",
    "row, col = data.edge_index\n",
    "adj = get_adj(row, col, N)\n",
    "\n",
    "# preprocessing of features\n",
    "print('Diffusing node features')\n",
    "for _ in range(3):\n",
    "    x = adj @ x\n",
    "\n",
    "# rp = GaussianRandomProjection(n_components=dataset.num_features)\n",
    "# x = torch.from_numpy(rp.fit_transform(x))\n",
    "\n",
    "data.x = torch.from_numpy(x).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d360bfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing METIS partitioning...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch_geometric import loader\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "\n",
    "cluster_data = loader.ClusterData(data, num_parts=1000, recursive=False)\n",
    "\n",
    "# rp = GaussianRandomProjection(n_components=dataset.num_features)\n",
    "# cluster_data.data.x = torch.from_numpy(rp.fit_transform(cluster_data.data.x))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for cl in cluster_data:\n",
    "#         labels = torch.squeeze(cl.y).clone().detach()\n",
    "#         labels[cl.valid_mask] = -1\n",
    "#         labels[cl.test_mask] = -1\n",
    "        rp = GaussianRandomProjection(n_components=dataset.num_features)\n",
    "        cl.x = torch.from_numpy(rp.fit_transform(cl.x))\n",
    "\n",
    "op_dict = {}\n",
    "op_dict['embedding'] = cluster_data.data.x\n",
    "op_dict['label'] = cluster_data.data.y.to(torch.long)\n",
    "op_dict['train_idx'] = cluster_data.data.train_mask\n",
    "op_dict['valid_idx'] = cluster_data.data.valid_mask\n",
    "op_dict['test_idx'] = cluster_data.data.test_mask\n",
    "\n",
    "torch.save(op_dict, '{}.pt'.format(\"LAST_RP_CLUSTER\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9840382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(n_components=2)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8412b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
